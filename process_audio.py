import os
import json
import time
import random
import numpy as np
import pandas as pd
import torch
import subprocess  # <-- THAY THáº¾ cho '!'
import google.generativeai as genai
from google.generativeai.types import GenerationConfig
from faster_whisper import WhisperModel

# -----------------------------------------------
# CÃ€I Äáº¶T SEED VÃ€ CÃC BIáº¾N TOÃ€N Cá»¤C
# -----------------------------------------------

SEED_VALUE = 42
torch.manual_seed(SEED_VALUE)
np.random.seed(SEED_VALUE)
random.seed(SEED_VALUE)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED_VALUE)

# -----------------------------------------------
# KHá»žI Táº O GEMINI (CHáº Y 1 Láº¦N)
# -----------------------------------------------

# PROMPT ÄÃƒ RÃšT Gá»ŒN (Lá»±a chá»n 1)
SYSTEM_PROMPT = """
Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn nghiá»‡p, nhiá»‡m vá»¥ cá»§a báº¡n lÃ  trÃ­ch xuáº¥t thÃ´ng tin Ä‘Æ¡n hÃ ng
tá»« má»™t Ä‘oáº¡n vÄƒn báº£n phiÃªn Ã¢m (transcript).

YÃªu cáº§u:
1. PhÃ¢n tÃ­ch ká»¹ vÄƒn báº£n Ä‘Æ°á»£c cung cáº¥p.
2. XÃ¡c Ä‘á»‹nh Táº¤T Cáº¢ cÃ¡c sáº£n pháº©m Ä‘Æ°á»£c Ä‘á» cáº­p.
3. Vá»›i má»—i sáº£n pháº©m, trÃ­ch xuáº¥t chÃ­nh xÃ¡c: TÃªn sáº£n pháº©m, Sá»‘ lÆ°á»£ng (pháº£i lÃ  Sá»), vÃ  ÄÆ¡n vá»‹ tÃ­nh.
4. Tráº£ lá»i CHÃNH XÃC dÆ°á»›i dáº¡ng má»™t máº£ng JSON (JSON array).
5. KHÃ”NG thÃªm báº¥t ká»³ vÄƒn báº£n nÃ o khÃ¡c ngoÃ i máº£ng JSON.

VÃ­ dá»¥ Ä‘á»‹nh dáº¡ng JSON mong muá»‘n:
[
  {"ten_san_pham": "TÃªn A", "so_luong": 10, "don_vi": "thÃ¹ng"},
  {"ten_san_pham": "Sáº£n pháº©m B", "so_luong": 5, "don_vi": "cÃ¡i"}
]
"""

# Define JSON (schema)
output_schema = {
    "type": "ARRAY",
    "items": {
        "type": "OBJECT",
        "properties": {
            "ten_san_pham": {"type": "STRING"},
            "so_luong": {"type": "NUMBER"},
            "don_vi": {"type": "STRING"}
        },
        "required": ["ten_san_pham", "so_luong", "don_vi"]
    }
}

# Biáº¿n toÃ n cá»¥c cho model
gemini_model_global = None
gemini_config_global = None

# -----------------------------------------------
# UTILS
# -----------------------------------------------

def initialize_gemini():
    """
    Äá»c API key tá»« biáº¿n mÃ´i trÆ°á»ng vÃ  khá»Ÿi táº¡o model Gemini.
    """
    global gemini_model_global, gemini_config_global
    try:
        # THAY Äá»”I QUAN TRá»ŒNG: Äá»c tá»« Biáº¿n mÃ´i trÆ°á»ng
        api_key = os.environ.get('GOOGLE_API_KEY')
        if not api_key:
            print("Lá»–I: Biáº¿n mÃ´i trÆ°á»ng 'GOOGLE_API_KEY' khÃ´ng Ä‘Æ°á»£c tÃ¬m tháº¥y.")
            print("HÃ£y cháº¡y 'export GOOGLE_API_KEY=your_key_here' trÆ°á»›c khi cháº¡y script.")
            return False
            
        genai.configure(api_key=api_key)

        gemini_model_global = genai.GenerativeModel(
            model_name="gemini-2.0-flash",
            system_instruction=SYSTEM_PROMPT
        )
        gemini_config_global = GenerationConfig(
            response_mime_type="application/json",
            response_schema=output_schema
        )
        print("âœ… Gemini model vÃ  config Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o.")
        return True
        
    except Exception as e:
        print(f"Lá»–I: KhÃ´ng thá»ƒ khá»Ÿi táº¡o Gemini: {e}")
        return False


def extract_products_with_gemini(transcript_text, max_retries=3):
    """
    Gá»­i vÄƒn báº£n Ä‘áº¿n Gemini, sá»­ dá»¥ng model vÃ  config toÃ n cá»¥c.
    Bao gá»“m cÆ¡ cháº¿ tá»± Ä‘á»™ng thá»­ láº¡i (retry) khi gáº·p lá»—i 429.
    """
    if not transcript_text:
        print("Input text is empty, skipping API call.")
        return None
        
    if not gemini_model_global or not gemini_config_global:
        print("Lá»–I: Model Gemini chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o.")
        return None

    wait_time = 5 # Thá»i gian chá» ban Ä‘áº§u
    
    for attempt in range(max_retries):
        try:
            response = gemini_model_global.generate_content(
                transcript_text,
                generation_config=gemini_config_global
            )
            parsed_data = json.loads(response.text)
            return parsed_data # ThÃ nh cÃ´ng

        except Exception as e:
            if "429" in str(e) and attempt < max_retries - 1:
                print(f"âš ï¸ WARNING: Rate Limit (429). Chá» {wait_time}s... (Láº§n {attempt + 1})")
                time.sleep(wait_time)
                wait_time *= 2
            else:
                print(f"âŒ ERROR while calling Gemini API (khÃ´ng thá»ƒ phá»¥c há»“i): {e}")
                if "response" in locals():
                    print(f"Returned content: {response.text}")
                return None
    return None


def save_to_excel(data, excel_path):
    """
    LÆ°u dá»¯ liá»‡u DataFrame ra file Excel.
    """
    if not data:
        print("KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ lÆ°u ra Excel.")
        return

    try:
        df = pd.DataFrame(data)
        df = df[["ten_san_pham", "so_luong", "don_vi"]] # Äáº£m báº£o Ä‘Ãºng thá»© tá»± cá»™t
        df.to_excel(excel_path, index=False)
        print(f"âœ… Excel file saved successfully!\nFilepath: {excel_path}")
    except Exception as e:
        print(f"âŒ ERROR while saving Excel file: {e}")


def load_whisper_model(model_size):
    """
    Táº£i model Whisper (Ä‘Ã£ tá»‘i Æ°u).
    """
    device = "cuda" if torch.cuda.is_available() else "cpu"
    compute_type = "float16" if device == "cuda" else "default"
    
    print(f"Äang táº£i Whisper model '{model_size}' (device: {device}, compute: {compute_type})...")
    try:
        model = WhisperModel(model_size, device=device, compute_type=compute_type)
        print("âœ… Whisper model loaded.")
        return model
    except Exception as e:
        print(f"âŒ Lá»–I khi táº£i model Whisper: {e}")
        return None

def get_audio_duration(audio_path):
    """
    THAY THáº¾ cho !ffprobe: DÃ¹ng subprocess Ä‘á»ƒ láº¥y thá»i lÆ°á»£ng audio.
    """
    try:
        cmd = [
            "ffprobe",
            "-v", "quiet",
            "-print_format", "json",
            "-show_format",
            audio_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        probe_data = json.loads(result.stdout)
        return float(probe_data['format']['duration'])
    except FileNotFoundError:
        print("âŒ Lá»–I: Lá»‡nh 'ffprobe' khÃ´ng tÃ¬m tháº¥y. HÃ£y Ä‘áº£m báº£o FFmpeg Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t.")
        return None
    except Exception as e:
        print(f"âš ï¸ WARNING: KhÃ´ng thá»ƒ láº¥y thá»i lÆ°á»£ng audio: {e}")
        return None

# -----------------------------------------------
# HÃ€M Xá»¬ LÃ CHÃNH
# -----------------------------------------------

def process_single_file(whisper_model, audio_path, excel_output_path):
    """
    Cháº¡y toÃ n bá»™ pipeline cho 1 file audio.
    """
    print("-" * 50)
    print(f"Báº¯t Ä‘áº§u xá»­ lÃ½ file: {audio_path}")
    total_start_time = time.time()

    # Táº¡o thÆ° má»¥c output náº¿u chÆ°a cÃ³
    try:
        TRANSCRIPT_PATH = os.path.dirname(excel_output_path)
        os.makedirs(TRANSCRIPT_PATH, exist_ok=True)
    except Exception as e:
        print(f"Lá»—i khi táº¡o thÆ° má»¥c: {e}")
        return

    # Láº¥y thá»i lÆ°á»£ng (tÃ¹y chá»n)
    # audio_duration = get_audio_duration(audio_path)
    # if audio_duration:
    #     print(f"Audio duration: {audio_duration:.2f}s")

    # ----- PHASE 1: WHISPER (tá»« model "small") -----
    phase1_start = time.time()
    try:
        segments, info = whisper_model.transcribe(
            audio_path,
            language="vi",
            vad_filter=True,
            word_timestamps=True,
            condition_on_previous_text=False,
            beam_size=5,
            temperature=0,
        )
        segments_list = list(segments)
        phase1_end = time.time()
        print(f"â±ï¸ phase 1 (Whisper): {(phase1_end - phase1_start):.3f} sec")
    except Exception as e:
        print(f"âŒ Lá»–I trong Phase 1 (Whisper): {e}")
        return

    # ----- Bá»Ž HOÃ€N TOÃ€N PHASE 1B (GHI JSON) -----

    # ----- PHASE 2: GEMINI (tá»« bá»™ nhá»›) -----
    phase2_start = time.time()

    # Táº O TEXT TRá»°C TIáº¾P Tá»ª Bá»˜ NHá»š
    transcript_text = " ".join([segment.text.strip() for segment in segments_list])

    if transcript_text:
        extracted_data = extract_products_with_gemini(transcript_text)
        if extracted_data:
            save_to_excel(extracted_data, excel_output_path)
        else:
            print("âš ï¸ Gemini API call failed or returned no data.")
    else:
        print("âš ï¸ Whisper returned an empty transcript.")

    phase2_end = time.time()
    print(f"â±ï¸ phase 2 (Gemini + Excel): {(phase2_end - phase2_start):.3f} sec")

    total_end_time = time.time()
    print(f"ðŸŽ‰ ** Total processed time: {(total_end_time - total_start_time):.3f} sec **")
    print("-" * 50)


# -----------------------------------------------
# ÄIá»‚M Báº®T Äáº¦U CHáº Y SCRIPT
# -----------------------------------------------

if __name__ == "__main__":
    # --- PATH ---
    AUDIO_FILE = "sample_audio/2.wav" 
    EXCEL_OUTPUT = "transcripts/2_wav_gemini_order.xlsx"

    # 1. Khá»Ÿi táº¡o whisper + gemini
    whisper_model = load_whisper_model(model_size="medium")
    gemini_ready = initialize_gemini()

    # 2. main 
    if whisper_model and gemini_ready:
        process_single_file(whisper_model, AUDIO_FILE, EXCEL_OUTPUT)
    else:
        print("âŒ Lá»–I: KhÃ´ng thá»ƒ khá»Ÿi táº¡o model, script bá»‹ dá»«ng.")

        # quan dzai t1win 